{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dog_Breed_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c4SO7-PokU9",
        "colab_type": "code",
        "outputId": "cd3746c3-c03c-4be3-96d8-5004bb0ff6a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmVHFmQU207R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/gdrive/My Drive/dog-breed')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5byFJ0jB3CyK",
        "colab_type": "code",
        "outputId": "cabd83e1-22ca-40d4-a942-c1ad5533c01c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Copy of dogImages.zip'  'Dog Breed Classifier.zip'   lfw\t report.html\n",
            " dog_app.html\t\t  dogImages\t\t      lfw.zip\n",
            " dog_app.ipynb\t\t  dogImages.zip\t\t      __MACOSX\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsQyRje93FOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql171IgU1-ED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size=224"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0aMJ2Ts0kX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation([-30, 30]),\n",
        "        transforms.Resize((input_size,input_size)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCSNGNkY2HuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = torchvision.datasets.ImageFolder(root=\"/gdrive/My Drive/dog-breed/dogImages/train\", transform=data_transforms['train'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDrk8Vg-iTeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_data= torchvision.datasets.ImageFolder(root=\"/gdrive/My Drive/dog-breed/dogImages/valid\", transform=data_transforms['valid'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExrWJh0b29DS",
        "colab_type": "code",
        "outputId": "120882ac-ea1a-4c65-bb49-44995fa457de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_data),len(valid_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6680, 835)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y8wMUgg3GAI",
        "colab_type": "code",
        "outputId": "7e88625f-4e89-4fde-8008-47ccd7d1f8c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_data.classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "133"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-CBk58bjhOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg3lb4nOjZZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl=DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "valid_dl=DataLoader(valid_data, batch_size=32, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7ZxxqZekkXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loaders={'train':train_dl,'valid':valid_dl}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT1DftJ24aRZ",
        "colab_type": "code",
        "outputId": "82cef73c-127b-4277-ae2c-cbc7f851ed23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_data.classes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['001.Affenpinscher',\n",
              " '002.Afghan_hound',\n",
              " '003.Airedale_terrier',\n",
              " '004.Akita',\n",
              " '005.Alaskan_malamute',\n",
              " '006.American_eskimo_dog',\n",
              " '007.American_foxhound',\n",
              " '008.American_staffordshire_terrier',\n",
              " '009.American_water_spaniel',\n",
              " '010.Anatolian_shepherd_dog',\n",
              " '011.Australian_cattle_dog',\n",
              " '012.Australian_shepherd',\n",
              " '013.Australian_terrier',\n",
              " '014.Basenji',\n",
              " '015.Basset_hound',\n",
              " '016.Beagle',\n",
              " '017.Bearded_collie',\n",
              " '018.Beauceron',\n",
              " '019.Bedlington_terrier',\n",
              " '020.Belgian_malinois',\n",
              " '021.Belgian_sheepdog',\n",
              " '022.Belgian_tervuren',\n",
              " '023.Bernese_mountain_dog',\n",
              " '024.Bichon_frise',\n",
              " '025.Black_and_tan_coonhound',\n",
              " '026.Black_russian_terrier',\n",
              " '027.Bloodhound',\n",
              " '028.Bluetick_coonhound',\n",
              " '029.Border_collie',\n",
              " '030.Border_terrier',\n",
              " '031.Borzoi',\n",
              " '032.Boston_terrier',\n",
              " '033.Bouvier_des_flandres',\n",
              " '034.Boxer',\n",
              " '035.Boykin_spaniel',\n",
              " '036.Briard',\n",
              " '037.Brittany',\n",
              " '038.Brussels_griffon',\n",
              " '039.Bull_terrier',\n",
              " '040.Bulldog',\n",
              " '041.Bullmastiff',\n",
              " '042.Cairn_terrier',\n",
              " '043.Canaan_dog',\n",
              " '044.Cane_corso',\n",
              " '045.Cardigan_welsh_corgi',\n",
              " '046.Cavalier_king_charles_spaniel',\n",
              " '047.Chesapeake_bay_retriever',\n",
              " '048.Chihuahua',\n",
              " '049.Chinese_crested',\n",
              " '050.Chinese_shar-pei',\n",
              " '051.Chow_chow',\n",
              " '052.Clumber_spaniel',\n",
              " '053.Cocker_spaniel',\n",
              " '054.Collie',\n",
              " '055.Curly-coated_retriever',\n",
              " '056.Dachshund',\n",
              " '057.Dalmatian',\n",
              " '058.Dandie_dinmont_terrier',\n",
              " '059.Doberman_pinscher',\n",
              " '060.Dogue_de_bordeaux',\n",
              " '061.English_cocker_spaniel',\n",
              " '062.English_setter',\n",
              " '063.English_springer_spaniel',\n",
              " '064.English_toy_spaniel',\n",
              " '065.Entlebucher_mountain_dog',\n",
              " '066.Field_spaniel',\n",
              " '067.Finnish_spitz',\n",
              " '068.Flat-coated_retriever',\n",
              " '069.French_bulldog',\n",
              " '070.German_pinscher',\n",
              " '071.German_shepherd_dog',\n",
              " '072.German_shorthaired_pointer',\n",
              " '073.German_wirehaired_pointer',\n",
              " '074.Giant_schnauzer',\n",
              " '075.Glen_of_imaal_terrier',\n",
              " '076.Golden_retriever',\n",
              " '077.Gordon_setter',\n",
              " '078.Great_dane',\n",
              " '079.Great_pyrenees',\n",
              " '080.Greater_swiss_mountain_dog',\n",
              " '081.Greyhound',\n",
              " '082.Havanese',\n",
              " '083.Ibizan_hound',\n",
              " '084.Icelandic_sheepdog',\n",
              " '085.Irish_red_and_white_setter',\n",
              " '086.Irish_setter',\n",
              " '087.Irish_terrier',\n",
              " '088.Irish_water_spaniel',\n",
              " '089.Irish_wolfhound',\n",
              " '090.Italian_greyhound',\n",
              " '091.Japanese_chin',\n",
              " '092.Keeshond',\n",
              " '093.Kerry_blue_terrier',\n",
              " '094.Komondor',\n",
              " '095.Kuvasz',\n",
              " '096.Labrador_retriever',\n",
              " '097.Lakeland_terrier',\n",
              " '098.Leonberger',\n",
              " '099.Lhasa_apso',\n",
              " '100.Lowchen',\n",
              " '101.Maltese',\n",
              " '102.Manchester_terrier',\n",
              " '103.Mastiff',\n",
              " '104.Miniature_schnauzer',\n",
              " '105.Neapolitan_mastiff',\n",
              " '106.Newfoundland',\n",
              " '107.Norfolk_terrier',\n",
              " '108.Norwegian_buhund',\n",
              " '109.Norwegian_elkhound',\n",
              " '110.Norwegian_lundehund',\n",
              " '111.Norwich_terrier',\n",
              " '112.Nova_scotia_duck_tolling_retriever',\n",
              " '113.Old_english_sheepdog',\n",
              " '114.Otterhound',\n",
              " '115.Papillon',\n",
              " '116.Parson_russell_terrier',\n",
              " '117.Pekingese',\n",
              " '118.Pembroke_welsh_corgi',\n",
              " '119.Petit_basset_griffon_vendeen',\n",
              " '120.Pharaoh_hound',\n",
              " '121.Plott',\n",
              " '122.Pointer',\n",
              " '123.Pomeranian',\n",
              " '124.Poodle',\n",
              " '125.Portuguese_water_dog',\n",
              " '126.Saint_bernard',\n",
              " '127.Silky_terrier',\n",
              " '128.Smooth_fox_terrier',\n",
              " '129.Tibetan_mastiff',\n",
              " '130.Welsh_springer_spaniel',\n",
              " '131.Wirehaired_pointing_griffon',\n",
              " '132.Xoloitzcuintli',\n",
              " '133.Yorkshire_terrier']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc-8yndM3qkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets, models, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYPUI7QdPXhc",
        "colab_type": "code",
        "outputId": "09bfe774-64b9-4662-e36f-63c575391878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "resnet18 = models.resnet18(pretrained=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
            "100%|██████████| 44.7M/44.7M [00:02<00:00, 21.6MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XermSPslPnZx",
        "colab_type": "code",
        "outputId": "e9780195-3c72-404c-ee58-7aaa53603021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "resnet18"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRMOCAdoPqKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet18.fc = nn.Linear(512, len(train_data.classes))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE8KJXu2P5A-",
        "colab_type": "code",
        "outputId": "0a5c131f-b70a-46f3-95e7-0041700ebe5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "resnet18"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=133, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbvMDmSZQC-z",
        "colab_type": "code",
        "outputId": "aca2f730-2bd6-4963-cef6-52e6f707c86a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCL2bduxQ_ED",
        "colab_type": "code",
        "outputId": "6139e49a-5ca9-4ed6-d596-ee55abe32650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "resnet18.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=133, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6LoDt7BSV2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTGbkJqcc2Hn",
        "colab_type": "code",
        "outputId": "ca09f344-9ea4-4665-b7fa-2cd8cbf47742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64avdQMGd2Vk",
        "colab_type": "code",
        "outputId": "bf4e48a7-660b-41c6-9083-1b2feb34ba7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/gdrive/My Drive/dog-breed'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54hIadpkdDAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FocalLoss(torch.nn.Module):\n",
        "    def __init__(self, gamma=2):\n",
        "        super().__init__()\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, log_pred_prob_onehot, target):\n",
        "        pred_prob_oh = torch.exp(log_pred_prob_onehot)\n",
        "        pt = Variable(pred_prob_oh.data.gather(1, target.data.view(-1, 1)), requires_grad=True)\n",
        "        modulator = (1 - pt) ** self.gamma\n",
        "        mce = modulator * (-torch.log(pt))\n",
        "\n",
        "        return mce.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu_im7MJc3i_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion=FocalLoss()\n",
        "optimizer = torch.optim.Adam(resnet18.parameters(), lr=0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvht6ydEc8X_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "    \n",
        "    best_path='best_val_acc.pth'\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'valid']:\n",
        "            \n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "#                 print('1st batch')\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                   \n",
        "                    if is_inception and phase == 'train':\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            if phase == 'valid' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                torch.save(model.state_dict(), best_path)\n",
        "            if phase == 'valid':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHM_ueIKlE4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import copy\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MGDo-RNoXJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gfHHhMCdytE",
        "colab_type": "code",
        "outputId": "440e3284-e531-43b9-976f-16fa0b59e419",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "ind=0\n",
        "error_count=0\n",
        "for root,dirs,files in os.walk('/gdrive/My Drive/dog-breed/dogImages/'):\n",
        "    for file in files:\n",
        "        f=os.path.join(root,file)\n",
        "        ind+=1\n",
        "        img=Image.open(f)\n",
        "        if ind%1000==0:\n",
        "            print(ind,'-------------------------------------')\n",
        "        try:\n",
        "            if not list(data_transforms['train'](img).size())==[3, 224, 224]:\n",
        "                print('error')\n",
        "                shutil.move(f,'./error_files/'+file)\n",
        "        except Exception as e:\n",
        "            error_count+=1\n",
        "            shutil.move(f,'./error_files/'+f.split('/')[3]+'/'+file)\n",
        "            print(e)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 -------------------------------------\n",
            "2000 -------------------------------------\n",
            "3000 -------------------------------------\n",
            "4000 -------------------------------------\n",
            "5000 -------------------------------------\n",
            "6000 -------------------------------------\n",
            "7000 -------------------------------------\n",
            "8000 -------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvWuWr0zk5pJ",
        "colab_type": "code",
        "outputId": "7e4ccaf4-3652-43cc-88b3-59d87c7bd3d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model, val_acc_history=train_model(resnet18,data_loaders, criterion, optimizer, num_epochs=25, is_inception=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: -1.0499 Acc: 0.0067\n",
            "valid Loss: -0.9283 Acc: 0.0060\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: -0.9249 Acc: 0.0060\n",
            "valid Loss: -0.8952 Acc: 0.0060\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: -1.0087 Acc: 0.0076\n",
            "valid Loss: -1.0060 Acc: 0.0060\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: -0.9932 Acc: 0.0082\n",
            "valid Loss: -0.9327 Acc: 0.0060\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: -1.0061 Acc: 0.0061\n",
            "valid Loss: -0.9152 Acc: 0.0060\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: -0.9544 Acc: 0.0063\n",
            "valid Loss: -0.9732 Acc: 0.0048\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: -0.9762 Acc: 0.0052\n",
            "valid Loss: -0.9707 Acc: 0.0060\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: -0.9169 Acc: 0.0054\n",
            "valid Loss: -0.9891 Acc: 0.0060\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: -1.0364 Acc: 0.0067\n",
            "valid Loss: -0.9359 Acc: 0.0048\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: -0.9888 Acc: 0.0069\n",
            "valid Loss: -0.9263 Acc: 0.0048\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: -0.9777 Acc: 0.0076\n",
            "valid Loss: -0.9744 Acc: 0.0048\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: -0.9610 Acc: 0.0073\n",
            "valid Loss: -0.8878 Acc: 0.0060\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: -0.9249 Acc: 0.0057\n",
            "valid Loss: -0.9175 Acc: 0.0060\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: -0.9306 Acc: 0.0067\n",
            "valid Loss: -0.9371 Acc: 0.0060\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: -0.9696 Acc: 0.0069\n",
            "valid Loss: -0.8766 Acc: 0.0048\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: -0.9403 Acc: 0.0070\n",
            "valid Loss: -0.8956 Acc: 0.0060\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: -1.0468 Acc: 0.0075\n",
            "valid Loss: -0.9649 Acc: 0.0060\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: -0.9904 Acc: 0.0063\n",
            "valid Loss: -0.9854 Acc: 0.0048\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: -0.9382 Acc: 0.0072\n",
            "valid Loss: -0.9271 Acc: 0.0060\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: -0.9212 Acc: 0.0061\n",
            "valid Loss: -0.9523 Acc: 0.0048\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: -0.9371 Acc: 0.0073\n",
            "valid Loss: -0.9316 Acc: 0.0048\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: -0.9898 Acc: 0.0057\n",
            "valid Loss: -0.9357 Acc: 0.0060\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: -0.9144 Acc: 0.0058\n",
            "valid Loss: -0.8622 Acc: 0.0060\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: -0.9170 Acc: 0.0058\n",
            "valid Loss: -0.9425 Acc: 0.0048\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: -0.9595 Acc: 0.0064\n",
            "valid Loss: -0.8427 Acc: 0.0048\n",
            "\n",
            "Training complete in 50m 29s\n",
            "Best val Acc: 0.005988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7PUqoPElBmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}